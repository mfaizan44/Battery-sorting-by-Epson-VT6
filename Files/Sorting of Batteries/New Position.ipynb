{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2340e492-19a7-4350-a47e-876f3d28ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 261.2ms\n",
      "Speed: 5.3ms preprocess, 261.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 191.7ms\n",
      "Speed: 4.0ms preprocess, 191.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 201.2ms\n",
      "Speed: 3.6ms preprocess, 201.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 D type, 174.1ms\n",
      "Speed: 3.0ms preprocess, 174.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected D type at new coordinates (518, 274, 162)\n",
      "\n",
      "0: 480x640 1 D type, 190.0ms\n",
      "Speed: 4.6ms preprocess, 190.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected D type at new coordinates (502, 251, 162)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 202.1ms\n",
      "Speed: 3.4ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected AA at new coordinates (548, 268, 162)\n",
      "Detected D type at new coordinates (548, 268, 162)\n",
      "\n",
      "0: 480x640 1 AA, 1 9v, 191.2ms\n",
      "Speed: 5.1ms preprocess, 191.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected AA at new coordinates (456, 262, 162)\n",
      "Detected 9v at new coordinates (456, 262, 162)\n",
      "\n",
      "0: 480x640 1 AA, 1 9v, 185.0ms\n",
      "Speed: 3.6ms preprocess, 185.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected AA at new coordinates (456, 262, 162)\n",
      "Detected 9v at new coordinates (456, 262, 162)\n",
      "\n",
      "0: 480x640 1 AA, 1 9v, 185.9ms\n",
      "Speed: 5.0ms preprocess, 185.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected AA at new coordinates (456, 262, 162)\n",
      "Detected 9v at new coordinates (456, 262, 162)\n",
      "\n",
      "0: 480x640 1 AA, 1 9v, 199.8ms\n",
      "Speed: 3.0ms preprocess, 199.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected AA at new coordinates (456, 262, 162)\n",
      "Detected 9v at new coordinates (456, 262, 162)\n",
      "Detection stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time  # Import for adding delay\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "model = YOLO('best.pt')  # Replace with 'yolov8n.pt' if needed\n",
    "\n",
    "# Load corner points calibration data\n",
    "corner_points = np.load('corner_points.npz')['corner_points']\n",
    "tl, tr, bl, br = corner_points[:4]\n",
    "\n",
    "# Define class names (must match your trained model)\n",
    "class_names = ['AA', 'D type', '9v']\n",
    "\n",
    "# Initialize camera (adjust camera_index as needed)\n",
    "camera_index = 1  # Example: change this to match your external camera index\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open camera with index {camera_index}\")\n",
    "    exit()\n",
    "\n",
    "# Function to map detected position to normalized grid coordinates\n",
    "def map_to_grid(x, y, tl, tr, bl, br):\n",
    "    # Compute vectors for mapping to normalized grid coordinates\n",
    "    v1 = np.array([tr[0] - tl[0], tr[1] - tl[1]])\n",
    "    v2 = np.array([bl[0] - tl[0], bl[1] - tl[1]])\n",
    "    vp = np.array([x - tl[0], y - tl[1]])\n",
    "\n",
    "    # Calculate normalized grid coordinates (u, v)\n",
    "    u = np.dot(vp, v1) / np.dot(v1, v1)\n",
    "    v = np.dot(vp, v2) / np.dot(v2, v2)\n",
    "\n",
    "    return u, v\n",
    "\n",
    "# Function to convert grid coordinates to robot coordinates\n",
    "def grid_to_robot(u, v, tl, tr, bl, br):\n",
    "    # Calculate the robot coordinates (X, Y, Z) from the normalized grid coordinates (u, v)\n",
    "    x_robot = tl[0] + u * (tr[0] - tl[0]) + v * (bl[0] - tl[0])\n",
    "    y_robot = tl[1] + u * (tr[1] - tl[1]) + v * (bl[1] - tl[1])\n",
    "    z_robot = tl[2] + u * (tr[2] - tl[2]) + v * (bl[2] - tl[2])  # Adjust for height if necessary\n",
    "\n",
    "    return x_robot, y_robot, z_robot\n",
    "\n",
    "# Function to calculate X2, Y2, Z\n",
    "def calculate_X2_Y2(x1, y1, z1):\n",
    "    X2 = 0.71 * y1 + 351.32\n",
    "    Y2 = 0.5381 * x1 - 0.1054 * y1 + 78\n",
    "    Z2 = z1  # Z2 is the same as Z1\n",
    "    return int(X2), int(Y2), int(Z2)  # Convert to integers\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame)[0]  # Get the first result\n",
    "\n",
    "        # Iterate through the detected objects\n",
    "        detections = []\n",
    "        for result in results.boxes.data:\n",
    "            x1, y1, x2, y2, confidence, class_id = result.tolist()\n",
    "\n",
    "            # Calculate center coordinates of the bounding box\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "\n",
    "            # Map the detected position to the grid coordinates\n",
    "            u, v = map_to_grid(x_center, y_center, tl, tr, bl, br)\n",
    "\n",
    "            # Convert grid coordinates to robot coordinates\n",
    "            x_robot, y_robot, z_robot = grid_to_robot(u, v, tl, tr, bl, br)\n",
    "\n",
    "            # Calculate new X2, Y2, and Z based on the formula provided\n",
    "            new_X2, new_Y2, new_Z = calculate_X2_Y2(x_center, y_center, z_robot)\n",
    "\n",
    "            # Save detection information (battery type and new coordinates)\n",
    "            detections.append({\n",
    "                'battery_type': class_names[int(class_id)],\n",
    "                'new_coordinates': (new_X2, new_Y2, new_Z)\n",
    "            })\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "            label = f'{class_names[int(class_id)]} {confidence:.2f}'\n",
    "            cv2.putText(frame, label, (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "            # Display the new coordinates on the frame\n",
    "            coord_text = f'X2: {new_X2}, Y2: {new_Y2}, Z: {new_Z}'\n",
    "            cv2.putText(frame, coord_text, (int(x1), int(y2 + 20)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with detections and coordinates\n",
    "        cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "        # Print or log the detected battery information\n",
    "        for detection in detections:\n",
    "            print(f\"Detected {detection['battery_type']} at new coordinates {detection['new_coordinates']}\")\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Delay of 20 seconds\n",
    "        time.sleep(20)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detection stopped by user.\")\n",
    "finally:\n",
    "    # Release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37049da5-2f85-4989-ba80-72dab3a6313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 9v, 288.4ms\n",
      "Speed: 6.0ms preprocess, 288.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected 9v at new coordinates (551, 210, 162)\n",
      "\n",
      "0: 480x640 1 9v, 273.4ms\n",
      "Speed: 3.4ms preprocess, 273.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected 9v at new coordinates (550, 210, 162)\n",
      "\n",
      "0: 480x640 1 9v, 271.3ms\n",
      "Speed: 3.0ms preprocess, 271.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected 9v at new coordinates (550, 210, 162)\n",
      "\n",
      "0: 480x640 1 D type, 274.6ms\n",
      "Speed: 3.1ms preprocess, 274.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected D type at new coordinates (492, 226, 162)\n",
      "\n",
      "0: 480x640 1 D type, 284.3ms\n",
      "Speed: 5.0ms preprocess, 284.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected D type at new coordinates (492, 226, 162)\n",
      "\n",
      "0: 480x640 1 D type, 268.2ms\n",
      "Speed: 4.0ms preprocess, 268.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected D type at new coordinates (492, 226, 162)\n",
      "\n",
      "0: 480x640 1 D type, 298.3ms\n",
      "Speed: 5.5ms preprocess, 298.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected D type at new coordinates (491, 226, 162)\n",
      "Detection stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "model = YOLO('best.pt')  # Replace with 'yolov8n.pt' if needed\n",
    "\n",
    "# Load corner points calibration data\n",
    "corner_points = np.load('corner_points.npz')['corner_points']\n",
    "tl, tr, bl, br = corner_points[:4]\n",
    "\n",
    "# Define class names (must match your trained model)\n",
    "class_names = ['AA', 'D type', '9v']\n",
    "\n",
    "# Initialize camera (adjust camera_index as needed)\n",
    "camera_index = 1  # Example: change this to match your external camera index\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open camera with index {camera_index}\")\n",
    "    exit()\n",
    "\n",
    "# Function to map detected position to normalized grid coordinates\n",
    "def map_to_grid(x, y, tl, tr, bl, br):\n",
    "    # Compute vectors for mapping to normalized grid coordinates\n",
    "    v1 = np.array([tr[0] - tl[0], tr[1] - tl[1]])\n",
    "    v2 = np.array([bl[0] - tl[0], bl[1] - tl[1]])\n",
    "    vp = np.array([x - tl[0], y - tl[1]])\n",
    "\n",
    "    # Calculate normalized grid coordinates (u, v)\n",
    "    u = np.dot(vp, v1) / np.dot(v1, v1)\n",
    "    v = np.dot(vp, v2) / np.dot(v2, v2)\n",
    "\n",
    "    return u, v\n",
    "\n",
    "# Function to convert grid coordinates to robot coordinates\n",
    "def grid_to_robot(u, v, tl, tr, bl, br):\n",
    "    # Calculate the robot coordinates (X, Y, Z) from the normalized grid coordinates (u, v)\n",
    "    x_robot = tl[0] + u * (tr[0] - tl[0]) + v * (bl[0] - tl[0])\n",
    "    y_robot = tl[1] + u * (tr[1] - tl[1]) + v * (bl[1] - tl[1])\n",
    "    z_robot = tl[2] + u * (tr[2] - tl[2]) + v * (bl[2] - tl[2])  # Adjust for height if necessary\n",
    "\n",
    "    return x_robot, y_robot, z_robot\n",
    "\n",
    "# Function to calculate X2, Y2, Z\n",
    "def calculate_X2_Y2(x1, y1, z1):\n",
    "    X2 = 0.71 * y1 + 351.32\n",
    "    Y2 = 0.5381 * x1 - 0.1054 * y1 + 78\n",
    "    Z2 = z1  # Z2 is the same as Z1\n",
    "    return int(X2), int(Y2), int(Z2)  # Convert to integers\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Display the frame without detection\n",
    "        cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "        # Wait for spacebar ('space') press to trigger detection\n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "            # Perform inference when spacebar is pressed\n",
    "            results = model(frame)[0]  # Get the first result\n",
    "\n",
    "            # Iterate through the detected objects\n",
    "            detections = []\n",
    "            for result in results.boxes.data:\n",
    "                x1, y1, x2, y2, confidence, class_id = result.tolist()\n",
    "\n",
    "                # Calculate center coordinates of the bounding box\n",
    "                x_center = (x1 + x2) / 2\n",
    "                y_center = (y1 + y2) / 2\n",
    "\n",
    "                # Map the detected position to the grid coordinates\n",
    "                u, v = map_to_grid(x_center, y_center, tl, tr, bl, br)\n",
    "\n",
    "                # Convert grid coordinates to robot coordinates\n",
    "                x_robot, y_robot, z_robot = grid_to_robot(u, v, tl, tr, bl, br)\n",
    "\n",
    "                # Calculate new X2, Y2, and Z based on the formula provided\n",
    "                new_X2, new_Y2, new_Z = calculate_X2_Y2(x_center, y_center, z_robot)\n",
    "\n",
    "                # Save detection information (battery type and new coordinates)\n",
    "                detections.append({\n",
    "                    'battery_type': class_names[int(class_id)],\n",
    "                    'new_coordinates': (new_X2, new_Y2, new_Z)\n",
    "                })\n",
    "\n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "                label = f'{class_names[int(class_id)]} {confidence:.2f}'\n",
    "                cv2.putText(frame, label, (int(x1), int(y1 - 10)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Display the new coordinates on the frame\n",
    "                coord_text = f'X2: {new_X2}, Y2: {new_Y2}, Z: {new_Z}'\n",
    "                cv2.putText(frame, coord_text, (int(x1), int(y2 + 20)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the frame with detections and coordinates\n",
    "            cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "            # Print or log the detected battery information\n",
    "            for detection in detections:\n",
    "                print(f\"Detected {detection['battery_type']} at new coordinates {detection['new_coordinates']}\")\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detection stopped by user.\")\n",
    "finally:\n",
    "    # Release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088c7e03-ebc7-4acc-9504-9cfb320535b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "model = YOLO('best.pt')  # Replace with 'yolov8n.pt' if needed\n",
    "\n",
    "# Load corner points calibration data\n",
    "corner_points = np.load('corner_points.npz')['corner_points']\n",
    "tl, tr, bl, br = corner_points[:4]\n",
    "\n",
    "# Define class names (must match your trained model)\n",
    "class_names = ['AA', 'D type', '9v']\n",
    "\n",
    "# Initialize camera (adjust camera_index as needed)\n",
    "camera_index = 1  # Example: change this to match your external camera index\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open camera with index {camera_index}\")\n",
    "    exit()\n",
    "\n",
    "# Function to map detected position to normalized grid coordinates\n",
    "def map_to_grid(x, y, tl, tr, bl, br):\n",
    "    v1 = np.array([tr[0] - tl[0], tr[1] - tl[1]])\n",
    "    v2 = np.array([bl[0] - tl[0], bl[1] - tl[1]])\n",
    "    vp = np.array([x - tl[0], y - tl[1]])\n",
    "\n",
    "    u = np.dot(vp, v1) / np.dot(v1, v1)\n",
    "    v = np.dot(vp, v2) / np.dot(v2, v2)\n",
    "\n",
    "    return u, v\n",
    "\n",
    "# Function to convert grid coordinates to robot coordinates\n",
    "def grid_to_robot(u, v, tl, tr, bl, br):\n",
    "    x_robot = tl[0] + u * (tr[0] - tl[0]) + v * (bl[0] - tl[0])\n",
    "    y_robot = tl[1] + u * (tr[1] - tl[1]) + v * (bl[1] - tl[1])\n",
    "    z_robot = tl[2] + u * (tr[2] - tl[2]) + v * (bl[2] - tl[2])\n",
    "    return x_robot, y_robot, z_robot\n",
    "\n",
    "# Function to calculate X2, Y2, Z\n",
    "def calculate_X2_Y2(x1, y1, z1):\n",
    "    X2 = 0.71 * y1 + 351.32\n",
    "    Y2 = 0.5381 * x1 - 0.1054 * y1 + 78\n",
    "    Z2 = z1\n",
    "    return int(X2), int(Y2), int(Z2)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Display the frame without detection\n",
    "        cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "        # Wait for spacebar ('space') press to trigger detection\n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "            # Perform inference when spacebar is pressed\n",
    "            results = model(frame)[0]  # Get the first result\n",
    "\n",
    "            # Iterate through the detected objects\n",
    "            detections = []\n",
    "            for result in results.boxes.data:\n",
    "                x1, y1, x2, y2, confidence, class_id = result.tolist()\n",
    "\n",
    "                # Calculate center coordinates of the bounding box\n",
    "                x_center = (x1 + x2) / 2\n",
    "                y_center = (y1 + y2) / 2\n",
    "\n",
    "                # Map the detected position to the grid coordinates\n",
    "                u, v = map_to_grid(x_center, y_center, tl, tr, bl, br)\n",
    "\n",
    "                # Convert grid coordinates to robot coordinates\n",
    "                x_robot, y_robot, z_robot = grid_to_robot(u, v, tl, tr, bl, br)\n",
    "\n",
    "                # Calculate new X2, Y2, and Z based on the formula provided\n",
    "                new_X2, new_Y2, new_Z = calculate_X2_Y2(x_center, y_center, z_robot)\n",
    "\n",
    "                # Save detection information (battery type and new coordinates)\n",
    "                detections.append({\n",
    "                    'battery_type': class_names[int(class_id)],\n",
    "                    'new_coordinates': (new_X2, new_Y2, new_Z)\n",
    "                })\n",
    "\n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "                label = f'{class_names[int(class_id)]} {confidence:.2f}'\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Display the new coordinates on the frame\n",
    "                coord_text = f'X2: {new_X2}, Y2: {new_Y2}, Z: {new_Z}'\n",
    "                cv2.putText(frame, coord_text, (int(x1), int(y2) + 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the frame with detections and coordinates\n",
    "            cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "            # Print or log the detected battery information\n",
    "            for detection in detections:\n",
    "                print(f\"Detected {detection['battery_type']} at new coordinates {detection['new_coordinates']}\")\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detection stopped by user.\")\n",
    "finally:\n",
    "    # Release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab8759-25a5-4ccd-a5a8-0ea4fd3efa85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
