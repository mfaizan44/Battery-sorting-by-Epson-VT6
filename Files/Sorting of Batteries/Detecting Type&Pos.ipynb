{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a000ae-7696-4967-9666-2190e1102d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to capture image\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "model = YOLO('best.pt')  # Replace with 'yolov8n.pt' if needed\n",
    "\n",
    "# Load corner points calibration data\n",
    "corner_points = np.load('corner_points.npz')['corner_points']\n",
    "tl, tr, bl, br = corner_points[:4]\n",
    "\n",
    "# Define class names (must match your trained model)\n",
    "class_names = ['AA', 'D type', '9v']\n",
    "\n",
    "# Initialize camera (adjust camera_index as needed)\n",
    "camera_index = 1  # Example: change this to match your external camera index\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open camera with index {camera_index}\")\n",
    "    exit()\n",
    "\n",
    "# Function to map detected position to normalized grid coordinates\n",
    "def map_to_grid(x, y, tl, tr, bl, br):\n",
    "    # Compute vectors for mapping to normalized grid coordinates\n",
    "    v1 = np.array([tr[0] - tl[0], tr[1] - tl[1]])\n",
    "    v2 = np.array([bl[0] - tl[0], bl[1] - tl[1]])\n",
    "    vp = np.array([x - tl[0], y - tl[1]])\n",
    "\n",
    "    # Calculate normalized grid coordinates (u, v)\n",
    "    u = np.dot(vp, v1) / np.dot(v1, v1)\n",
    "    v = np.dot(vp, v2) / np.dot(v2, v2)\n",
    "\n",
    "    return u, v\n",
    "\n",
    "# Function to convert grid coordinates to robot coordinates\n",
    "def grid_to_robot(u, v, tl, tr, bl, br):\n",
    "    # Calculate the robot coordinates (X, Y, Z) from the normalized grid coordinates (u, v)\n",
    "    x_robot = tl[0] + u * (tr[0] - tl[0]) + v * (bl[0] - tl[0])\n",
    "    y_robot = tl[1] + u * (tr[1] - tl[1]) + v * (bl[1] - tl[1])\n",
    "    z_robot = tl[2] + u * (tr[2] - tl[2]) + v * (bl[2] - tl[2])  # Adjust for height if necessary\n",
    "\n",
    "    return x_robot, y_robot, z_robot\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame)[0]  # Get the first result\n",
    "\n",
    "        # Iterate through the detected objects\n",
    "        detections = []\n",
    "        for result in results.boxes.data:\n",
    "            x1, y1, x2, y2, confidence, class_id = result.tolist()\n",
    "\n",
    "            # Calculate center coordinates of the bounding box\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "\n",
    "            # Map the detected position to the grid coordinates\n",
    "            u, v = map_to_grid(x_center, y_center, tl, tr, bl, br)\n",
    "\n",
    "            # Convert grid coordinates to robot coordinates\n",
    "            x_robot, y_robot, z_robot = grid_to_robot(u, v, tl, tr, bl, br)\n",
    "\n",
    "            # Save detection information (battery type and coordinates)\n",
    "            detections.append({\n",
    "                'battery_type': class_names[int(class_id)],\n",
    "                'robot_coordinates': (x_robot, y_robot, z_robot)\n",
    "            })\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "            label = f'{class_names[int(class_id)]} {confidence:.2f}'\n",
    "            cv2.putText(frame, label, (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the frame with detections\n",
    "        cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "        # Print or log the detected battery information\n",
    "        for detection in detections:\n",
    "            print(f\"Detected {detection['battery_type']} at robot coordinates {detection['robot_coordinates']}\")\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detection stopped by user.\")\n",
    "finally:\n",
    "    # Release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75342efd-13ce-4f04-beff-e0196a015e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
