{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfe2f09-30d0-478f-aa02-093fc87b0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 296.3ms\n",
      "Speed: 23.2ms preprocess, 296.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 242.4ms\n",
      "Speed: 10.3ms preprocess, 242.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 237.5ms\n",
      "Speed: 4.7ms preprocess, 237.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 211.7ms\n",
      "Speed: 5.0ms preprocess, 211.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 223.3ms\n",
      "Speed: 10.1ms preprocess, 223.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 206.0ms\n",
      "Speed: 5.6ms preprocess, 206.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 216.8ms\n",
      "Speed: 6.0ms preprocess, 216.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 214.2ms\n",
      "Speed: 5.0ms preprocess, 214.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 214.7ms\n",
      "Speed: 3.7ms preprocess, 214.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 206.8ms\n",
      "Speed: 4.0ms preprocess, 206.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 185.7ms\n",
      "Speed: 4.0ms preprocess, 185.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 173.4ms\n",
      "Speed: 6.5ms preprocess, 173.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 172.0ms\n",
      "Speed: 4.3ms preprocess, 172.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 170.9ms\n",
      "Speed: 4.6ms preprocess, 170.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 179.8ms\n",
      "Speed: 7.7ms preprocess, 179.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 165.7ms\n",
      "Speed: 4.5ms preprocess, 165.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 181.8ms\n",
      "Speed: 4.3ms preprocess, 181.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 169.3ms\n",
      "Speed: 4.3ms preprocess, 169.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 172.3ms\n",
      "Speed: 5.4ms preprocess, 172.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 181.8ms\n",
      "Speed: 3.2ms preprocess, 181.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 178.0ms\n",
      "Speed: 4.3ms preprocess, 178.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 172.0ms\n",
      "Speed: 4.8ms preprocess, 172.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 174.6ms\n",
      "Speed: 6.8ms preprocess, 174.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 174.6ms\n",
      "Speed: 5.4ms preprocess, 174.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 176.6ms\n",
      "Speed: 3.6ms preprocess, 176.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 AA, 1 D type, 1 9v, 165.1ms\n",
      "Speed: 5.7ms preprocess, 165.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "model = YOLO('best.pt')  # Replace with 'yolov8n.pt' if needed\n",
    "\n",
    "# Define class names (must match your trained model)\n",
    "class_names = ['AA', 'D type', '9v']\n",
    "\n",
    "# Initialize camera (adjust camera_index as needed)\n",
    "camera_index = 1  # Example: change this to match your external camera index\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open camera with index {camera_index}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Capture frame-by-frame\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame)[0]  # Get the first result\n",
    "\n",
    "        # Iterate through the detected objects\n",
    "        for result in results.boxes.data:\n",
    "            x1, y1, x2, y2, confidence, class_id = result.tolist()\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "            label = f'{class_names[int(class_id)]} {confidence:.2f}'\n",
    "            cv2.putText(frame, label, (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the frame with detections\n",
    "        cv2.imshow('Battery Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detection stopped by user.\")\n",
    "finally:\n",
    "    # Release the capture and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a8fd5-24cc-455d-a4a6-e68cf7e19e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88203708-f83a-46f9-9ef3-5c9c4cca1b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
